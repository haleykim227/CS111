NAME: Seungwon Kim
EMAIL: haleykim@g.ucla.edu
ID: 405111152

Questions and Answers:

Question 2.1.1:
	 If the number of iterations is small enough, the thread can
	 execute its entire function within its single allotted time slice.
	 In this case, no critical section will be interrupted, race conditions
	 will not occur, and no final error will be present.

	 For the same reason given above, smaller number of iterations
	 seldom fail. There is a lower chance of a race condition occuring
	 with a small number of iterations.

Question 2.1.2:
	 --yield runs are much slower because now there is no chance of possibly
	 finishing the thread's work in one time slice. Every thread will be
	 interrupted midway, and switching takes time.

	 The additional time is spent switching between threads.

	 No, it is not possible get valid per-operations timings since we do not
	 know how much of the time is spent on switching between threads.

Question 2.1.3:
	 Creating threads are costly, but iterations are quick and efficient. Thus,
	 more iterations makes up for the overhead of creating a thread, and lowers the
	 final average cost per operation.

	 The plot seems to have an exponential decrease, which means there is an
	 asymptote at some point where it flattens. The "correct" number of iterations to
	 run would be when the graph hits this asymptote.

Question 2.1.4:
	 A smaller number of threads leads to less race conditions and lock contention.
	 Thus, they will be able to retrieve the lock with ease and the time spent
	 on actual work will be similar among the different options.

	 As the number of threads rise, there is more overhead, and each thread spends
	 more time waiting for their lock. Thus, the protected operations slow down.

Question 2.2.1:
	 In lab2_add-5.png, the per operation cost seems to increase with the number
	 of threads for the add operation, since the plot has a positive slope. On
	 the other hand, in lab2_list-4.png, the per operation cost seems to remain or
	 (slightly) decrease with the number of threads for the list operation.

	 The shapes of the plots are so different because (at least for my
	 implementation) of the thread operations for lists, the mutex locks for a large
	 chunk of time until all the operations are completed. Thus, context switches
	 are less often, and there is less overhead.

Question 2.2.2:
	 At first for a low number of threads, spin-locks seem to be more efficient.
	 However, as the number of threads increase, the cost per operations for the
	 spin-locks increases past the cost for mutexes.

	 This is because with a spin-lock, the CPU wastes time spinning and waiting,
	 while with a mutex, the CPU does not waste as much time on it when it discovers
	 that the mutex is locked.

Files Included in Submission lab2a-405111152.tar.gz:

